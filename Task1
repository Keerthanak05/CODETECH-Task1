import gradio as gr
from diffusers import StableDiffusionPipeline
import torch

# Load the Stable Diffusion model
def load_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5", 
        torch_dtype=torch.float16 if device == "cuda" else torch.float32
    )
    pipe.to(device)
    return pipe

# Initialize the model
pipe = load_model()

# Define the function to generate and return an image
def generate_and_display(prompt):
    if not prompt.strip():
        return "Please enter a valid text prompt."
    try:
        # Generate the image
        result = pipe(prompt, num_inference_steps=50)  # Adjust steps for quality/speed trade-off
        return result.images[0]  # Return the first generated image
    except Exception as e:
        return f"Error generating image: {str(e)}"

# Create the Gradio interface
interface = gr.Interface(
    fn=generate_and_display,
    inputs=gr.Textbox(lines=2, placeholder="Enter a descriptive prompt..."),
    outputs="image",
    title="Text-to-Image Generator",
    description="Generate an image based on a descriptive text prompt using Stable Diffusion.",
    examples=[
        "A futuristic city with flying cars and neon lights.",
        "A magical forest with glowing mushrooms and fairies.",
        "A tiger walking through a dense jungle at sunset.",
        "A steampunk airship floating above the clouds."
    ],
    allow_flagging="never"  # Disable flagging for simplicity
)

# Launch the app
if __name__ == "__main__":
    interface.launch(share=True)  # Set share=True to make the app accessible via a public link
